{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0aa8bf2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70019.90s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "Collecting rapidfuzz\n",
      "  Downloading rapidfuzz-3.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Downloading rapidfuzz-3.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hInstalling collected packages: rapidfuzz\n",
      "Successfully installed rapidfuzz-3.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install rapidfuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a9275b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GHG Categories: ['Scope_1_Fugitives', 'Scope_2_PurchasedEnergy', 'SScope_3_1_PurchasedGoods&Services_SpendBasedMethod']\n",
      "data/sample_GHG_data/Scope_1_Direct_Emissions_Fugitives.xlsx ‚Üí Scope_1_Fugitives | Ground Truth: Scope_1_Fugitives\n",
      "Summary saved to output_data/classify_aug20.xlsx\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import yaml\n",
    "from rapidfuzz import process  # modern replacement for fuzzywuzzy\n",
    "\n",
    "model = \"gemma3\"  # Specify your model here\n",
    "# Load the YAML file\n",
    "with open(\"data/templates/GHG_templates.yaml\", \"r\") as f:\n",
    "    templates = yaml.safe_load(f)\n",
    "\n",
    "data_folder = \"data/sample_GHG_data/\"\n",
    "data_files = glob.glob(os.path.join(data_folder, \"*.xlsx\"))\n",
    "\n",
    "GHG_categories = list(templates.keys())  # Assuming YAML file has GHG categories as keys\n",
    "print(\"GHG Categories:\", GHG_categories)\n",
    "\n",
    "def match_category(input_str, choices, threshold=80):\n",
    "    \"\"\"\n",
    "    Match input string to the closest category.\n",
    "    Returns best match if similarity >= threshold, else None.\n",
    "    \"\"\"\n",
    "    best_match, score, _ = process.extractOne(input_str, choices)\n",
    "    return best_match if score >= threshold else None\n",
    "\n",
    "# Initialize LLM once\n",
    "ollama = Ollama(\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    model=model\n",
    ")\n",
    "\n",
    "results = []\n",
    "\n",
    "for file in data_files[:1]:\n",
    "    df = pd.read_excel(file)\n",
    "\n",
    "    # Extract ground truth\n",
    "    if 'GHGCategory' in df.columns:\n",
    "        gt_value = str(df['GHGCategory'].iloc[0])\n",
    "    elif 'GHG Category' in df.columns:\n",
    "        gt_value = str(df['GHG Category'].iloc[0])\n",
    "    else:\n",
    "        gt_value = 'Not GHG-related'\n",
    "\n",
    "    # Prepare the prompt with sample data\n",
    "    sample_data = df.head(3).to_string(index=False)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Here are the first 3 rows of an Excel file:\n",
    "\n",
    "    {sample_data}\n",
    "\n",
    "    Analyze this sample data and classify it into one of the following GHG categories:\n",
    "\n",
    "    {GHG_categories}\n",
    "\n",
    "    Important rules:\n",
    "    - Respond with the exact category name from the list above.\n",
    "    - If none of the categories apply, respond with \"Not GHG-related\".\n",
    "    - Do not provide explanations, just the category name.\n",
    "    \"\"\"\n",
    "\n",
    "    # Call LLM\n",
    "    response = ollama.invoke(prompt).strip()\n",
    "    print(f\"{file} ‚Üí {response} | Ground Truth: {gt_value}\")\n",
    "\n",
    "    # Compare response with ground truth\n",
    "    matched = match_category(input_str=response, choices=[gt_value])\n",
    "    process_template = 'Yes' if matched else 'No'\n",
    "\n",
    "    # Collect result row\n",
    "    results.append({\n",
    "        \"Filename\": os.path.basename(file),\n",
    "        \"Response\": response,\n",
    "        \"Ground Truth\": gt_value,\n",
    "        \"process_template\": process_template\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save to Excel\n",
    "output_excel = \"output_data/classify_aug20.xlsx\"\n",
    "results_df.to_excel(output_excel, index=False)\n",
    "\n",
    "print(f\"Summary saved to {output_excel}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb76a5fd",
   "metadata": {},
   "source": [
    "# calculator payload mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3127e396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Failed to parse response for Scope_1_Direct_Emissions_Fugitives.xlsx: Extra data: line 98 column 1 (char 1808)\n",
      "‚úÖ Generated unknown payloads for Scope_1_Direct_Emissions_Fugitives.xlsx\n",
      "üéØ Saved generated payloads to output_data/template_payload_aug20_v2.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import ast\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "model = \"gemma3\"  # Specify your model here\n",
    "# Load results Excel\n",
    "output_excel = pd.read_excel(\"output_data/classify_aug20.xlsx\")\n",
    "\n",
    "# Load YAML once\n",
    "with open(\"data/templates/GHG_templates.yaml\", \"r\") as f:\n",
    "    templates = yaml.safe_load(f)\n",
    "\n",
    "data_folder = \"data/sample_GHG_data/\"\n",
    "ollama = Ollama(base_url=\"http://localhost:11434\", model=model)\n",
    "\n",
    "output_template_payload = {}\n",
    "\n",
    "for idx, row in output_excel.iterrows():\n",
    "    if row[\"process_template\"] == \"Yes\":\n",
    "        ground_truth = row[\"Ground Truth\"]\n",
    "        filename = row[\"Filename\"]\n",
    "\n",
    "        payload_template = templates.get(ground_truth, {})\n",
    "        scope_data = pd.read_excel(os.path.join(data_folder, filename))\n",
    "        n_rows = len(scope_data)\n",
    "\n",
    "        # Convert dataframe rows to JSON-style records\n",
    "        sample_data = scope_data.to_dict(orient=\"records\")\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        You are a data processing assistant. \n",
    "\n",
    "        I have an Excel file containing **{ground_truth}** data.  \n",
    "        Below is the payload template for each row:  \n",
    "\n",
    "        {payload_template}\n",
    "\n",
    "        Here are all {n_rows} rows from the Excel file as JSON records:\n",
    "        {sample_data}\n",
    "\n",
    "        For each row, generate **one dictionary** that fills in the template \n",
    "        using values from that row.  \n",
    "\n",
    "        Return a **Python list of {n_rows} dictionaries**, one per row.  \n",
    "        Do not add explanations. Do not wrap in code fences.  \n",
    "        \"\"\"\n",
    "\n",
    "        # Get response\n",
    "        response = ollama.invoke(prompt).strip()\n",
    "\n",
    "        # Clean up if model still adds code fences\n",
    "        if response.startswith(\"```\"):\n",
    "            response = response.strip(\"`\")\n",
    "            response = response.split(\"\\n\", 1)[-1]\n",
    "            response = response.rsplit(\"\\n\", 1)[0]\n",
    "\n",
    "        # Parse into Python list\n",
    "        try:\n",
    "            try:\n",
    "                parsed = ast.literal_eval(response)\n",
    "            except Exception:\n",
    "                parsed = json.loads(response)  # fallback if it's JSON\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Failed to parse response for {filename}: {e}\")\n",
    "            parsed = response\n",
    "\n",
    "        output_template_payload[filename] = parsed\n",
    "        print(f\"‚úÖ Generated {len(parsed) if isinstance(parsed, list) else 'unknown'} payloads for {filename}\")\n",
    "\n",
    "# Save to JSON\n",
    "output_json = \"output_data/template_payload_aug20_v2.json\"\n",
    "with open(output_json, \"w\") as f:\n",
    "    json.dump(output_template_payload, f, indent=4)\n",
    "\n",
    "print(f\"üéØ Saved generated payloads to {output_json}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea8836e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cb7bc79b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Scope_1_Direct_Emissions_Fugitives.xlsx': \"```python\\n[\\n    {'row_uuid': 'testmulti', 'facility_code': 'general insurance', 'invoice_no': '1', 'invoice_date': '2022-01-01', 'start_date': '2022-01-01', 'end_date': '2022-12-31', 'activity_amount': 'Actual', 'unit_id': 'testmulti', 'emission_type': 'activity data type', 'vehicle_fuel': 'vehicle name', 'number_of_vehicle': 'number of vehicles', 'cost': 'cost', 'currency': 'currency', 'supplier': 'supplier', 'description': 'notes', 'tag_id': ['tag1', 'tag2', '...'], 'link': 'evidence_url', 'link_name': 'evidence_name', 'link_note': 'evidence_note', 'Updatetype': 'System'}\\n]\\n```\"}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_template_payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ab5b48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
